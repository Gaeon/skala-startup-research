from fpdf import FPDF
from langchain.schema import SystemMessage
from langchain.chat_models import ChatOpenAI
from graphState import GraphState

from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(model="gpt-4o-mini")

# Report_Compiler
report_system_prompt = """ 
ë‹¹ì‹ ì€ ë²¤ì²˜ìºí”¼íƒˆ ë¶„ì„ê°€ë¡œ, AI ê¸°ë°˜ í—¬ìŠ¤ì¼€ì–´ ìŠ¤íƒ€íŠ¸ì—… 3ê³³ì— ëŒ€í•œ íˆ¬ìž í‰ê°€ ë³´ê³ ì„œë¥¼ ìž‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ìŒì€ ê° ìŠ¤íƒ€íŠ¸ì—…ì— ëŒ€í•œ ìš”ì•½ ì •ë³´, CEO ì •ë³´, ì‹œìž¥ ìƒí™©, ê²½ìŸì‚¬ ë¹„êµ, ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ í‰ê°€ ì ìˆ˜, ê·¸ë¦¬ê³  íˆ¬ìž íŒë‹¨ìž…ë‹ˆë‹¤.

ì´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ì¡°ê±´ì„ ì¶©ì¡±í•˜ëŠ” íˆ¬ìž í‰ê°€ ë³´ê³ ì„œë¥¼ ìž‘ì„±í•˜ì„¸ìš”:

1. ë³´ê³ ì„œ í˜•ì‹:
   - [1] ìŠ¤íƒ€íŠ¸ì—… ê°œìš”
   - [2] ê¸°ìˆ  ë° ì œí’ˆ ì†Œê°œ
   - [3] ì°½ì—…ìž ë° íŒ€ ì—­ëŸ‰
   - [4] ì‹œìž¥ í™˜ê²½ ë° ì„±ìž¥ ê°€ëŠ¥ì„±
   - [5] ê²½ìŸ ìš°ìœ„ ë° ì°¨ë³„í™” ìš”ì†Œ
   - [6] í‰ê°€ í•­ëª© ë¶„ì„ (checklist_scores ê¸°ë°˜)
   - [7] ì¢…í•© ì˜ê²¬ ë° íˆ¬ìž íŒë‹¨

2. ê° í•­ëª©ì€ êµ¬ì²´ì ì´ê³  ì •ëŸ‰ì  í˜¹ì€ ì •ì„±ì  ê·¼ê±°ë¥¼ í¬í•¨í•´ì•¼ í•˜ë©°, ë°ì´í„°ì— ê¸°ë°˜í•œ ë¶„ì„ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

3. ë¬¸ì²´ëŠ” ì „ë¬¸ì ì´ë˜, íˆ¬ìž ìœ„ì›íšŒ ë³´ê³ ì„œ í˜•ì‹ì„ ë”°ë¥´ì„¸ìš”. ê° í•­ëª©ì€ ê°„ê²°í•˜ì§€ë§Œ ëª…í™•í•œ ë…¼ë¦¬ ì „ê°œë¡œ ì„œìˆ í•©ë‹ˆë‹¤.

ë‹¤ìŒì€ í‰ê°€ì— ì‚¬ìš©í•  ë°ì´í„°ìž…ë‹ˆë‹¤:

{input}
"""

# ë³´ê³ ì„œ ìƒì„±
def generate_report_text(state: GraphState) -> str:
    messages = [SystemMessage(content=report_system_prompt.format(input=GraphState))]
    response = llm.invoke(messages)
    return response.content


def generate_pdf_report_from_text(report_text: str, output_path: str = "./startup_report.pdf") -> str:
    if not report_text:
        raise ValueError("ðŸš« report_textê°€ ë¹„ì–´ ìžˆìŠµë‹ˆë‹¤.")

    pdf = FPDF()
    pdf.add_page()
    pdf.add_font("malgun", "", "./malgun-gothic.ttf", uni=True)
    pdf.set_font("malgun", size=12)

    pdf.multi_cell(0, 8, report_text)
    pdf.output(output_path)

    return output_path
